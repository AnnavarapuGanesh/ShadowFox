# ğŸ”¥ ShadowFox AI/ML Internship - Weekly Tasks by Annavarapu Ganesh

Welcome to my ShadowFox Internship GitHub repository. This repository contains all the completed tasks for Weeks 1 to 3 of the AI/ML Internship Program, including implementation, explanations, and outputs.

---

## ğŸ‘¨â€ğŸ’» Author

**Name**: Annavarapu Ganesh  
**Email**: annavarapuganesh45@gmail.com  
**GitHub**: [github.com/AnnavarapuGanesh](https://github.com/AnnavarapuGanesh)  
**LinkedIn**: [linkedin.com/in/annavarapu-ganesh-4159732a5](https://www.linkedin.com/in/annavarapu-ganesh-4159732a5/)

---

## ğŸ“… Week 1: Boston House Price Prediction ğŸ 

### âœ… Objective
Build a regression model to predict house prices based on features like number of rooms, location, and area using the Boston housing dataset.

### ğŸ”§ Tech Stack
- Python
- Pandas, NumPy, Seaborn, Matplotlib
- Scikit-learn (Linear Regression, Decision Tree, Gradient Boosting)

### ğŸ“‚ Contents
- Data Cleaning
- Feature Scaling
- Outlier Handling
- Model Training & Evaluation
- Cross-Validation & Hyperparameter Tuning

### ğŸ“ˆ Outcome
Achieved optimized regression performance using ensemble methods and explained model evaluation using RÂ² Score and MAE.

---

## ğŸ“… Week 2: Loan Approval Prediction ğŸ¦

### âœ… Objective
Classify whether a loan will be approved based on customer features like income, credit history, employment status.

### ğŸ”§ Tech Stack
- Python
- Pandas, NumPy, Seaborn
- Scikit-learn (Logistic Regression, Random Forest, XGBoost)
- Label Encoding, OneHot Encoding, SMOTE

### ğŸ“‚ Contents
- Exploratory Data Analysis (EDA)
- Imbalanced Data Handling
- Model Training and ROC-AUC Evaluation
- Confusion Matrix & Classification Reports

### ğŸ“ˆ Outcome
Built a robust classification model with over 85% accuracy and ROC-AUC improvement using XGBoost.

---

## ğŸ“… Week 3: GPT-2 Text Generation with NLP ğŸ¤–

### âœ… Objective
Deploy and analyze a transformer-based language model (GPT-2) for various text generation tasks.

### ğŸ”§ Tech Stack
- Python
- HuggingFace Transformers (GPT-2)
- PyTorch
- Matplotlib, WordCloud

### ğŸ“‚ Features
- Implemented GPT-2 using HuggingFace
- Generated outputs from prompts across different domains
- Evaluated temperature effects and output length
- Visualized word count and model creativity

### ğŸ“Š Research Highlights
- Explored how temperature affects creativity vs coherence
- Compared GPT-2â€™s performance in technical, educational, and creative texts
- Benchmarked model speed and memory usage

### ğŸ“ˆ Results
GPT-2 generated high-quality, coherent responses with customizable creativity using temperature tuning.

---

## ğŸŒ Reference
- [roadmap.sh/ai-data-scientist](https://roadmap.sh/ai-data-scientist)

---


